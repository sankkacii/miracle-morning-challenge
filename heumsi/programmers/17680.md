```python
def solution(cacheSize, cities):
    cache = {}
    execution_time = 0
    for i, city in enumerate(cities):
        c = city.lower()
        if c in cache:
            execution_time += 1
            cache[c] = i
        else:
            execution_time += 5
            if cacheSize == 0:
                continue
            if len(cache) >= cacheSize:
                k, v = min(cache.items(), key=lambda x: x[1])
                cache.pop(k)
            cache[c] = i
    return execution_time
```

- LRU 캐시를 어떻게 구현하느냐 문제다.
- LRU 캐시는 실제로도 많이 쓰이는 방법이라 유용한 문제 같았다.
- `cache` 를 해시로 구현하여 `cache` 에서 탐색하는 시간을 `O(1)` 이 걸리도록 하였다.
- 단 Miss 가 나는 경우, `cache` 전체를 탐색(`O(n)`)해야 한다.
- 결국 전체 시간 복잡도는 `O(n^2)` 이 걸린다.
- **탐색하는데는 `O(1)` 걸리고, 순서를 보장하며 저장하는 방법은 없을까..?**
  - 궁금한데 무슨 키워드로 검색해야할지 모르겠다.
